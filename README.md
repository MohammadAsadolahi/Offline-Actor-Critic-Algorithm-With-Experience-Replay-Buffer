# Offline-Actor-Critic-Algorithm-With-Experience-Replay-Buffer
Combining experience replay buffer whith Actor-Critic algorithm to expedite learning procedure by offline learning
This codde is a single Actor-critic Agent deployed along with a experience replay buffer which is comonly used in off-policy reinforcement algorithms  
**this project can be applied for !any on-policy Actor-Critic algorithm! to expedite learning procedure**   
**this project is a research project and owners have no responsibility of any loss for deploying this project in real environmentn** 
WRITTEN BY MOHAMMAD ASADOLAHI  [feel free to ask any question in Issues or just email me]
Mohammad.E.Asadolahi@gmail.com  
https://github.com/mohammadAsadolahi  

**this code is not implemented with Pytorch! for TensorFlow version look up my Github repositories**
### to do:  
* write the ReplayBuffer code   
* [****Done!****] deploy Action space generation code
* [****Done!****] deploy the Agnet in tensorflow  
* [****Done!****] deploy the Environmetn class 
* [****Done!****] deploy the main learning loop
* [****Done!****] Deploy the test loop
